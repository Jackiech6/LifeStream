# Dockerfile for Video Processor Lambda Function
# Uses AWS Lambda Python base image for compatibility.
#
# Bake diarization + ASR models into the image so no HuggingFace/Whisper downloads at runtime.
# Build with: docker build --build-arg HF_TOKEN=<token> -f Dockerfile.processor .
# HF_TOKEN required for pyannote (baking). Omit to skip pyannote bake (runtime download).
#
# Dependencies used by processor (must all be installed):
#   Core: pydantic, pydantic-settings, python-dotenv, boto3, numpy, scipy, Pillow, click, tqdm
#   LLM/indexing: openai, pinecone (faiss-cpu omitted; use Pinecone in Lambda)
#   Media: opencv-python-headless, scenedetect, librosa, soundfile; ffmpeg/ffprobe (binary)
#   Audio: torch, torchaudio, whisper, tiktoken
#   Diarization: pyannote.audio, pyannote.core, pyannote.database, pyannote.pipeline, pyannote.metrics,
#                matplotlib, pytorch-metric-learning, scikit-learn (sklearn), asteroid-filterbanks (SincNet/PyanNet),
#                einops, huggingface-hub, pytorch-lightning, etc.

FROM public.ecr.aws/lambda/python:3.11

ARG HF_TOKEN
ENV PATH="/usr/local/bin:${PATH}"

# Install system dependencies required for video/audio processing
# Install build tools for compiling Python packages and tools for ffmpeg extraction.
# libsndfile: required by soundfile (Python) / pyannote for WAV load; provides libsndfile.so.
RUN yum update -y && \
    yum install -y \
    gcc \
    gcc-c++ \
    make \
    git \
    curl \
    tar \
    xz \
    python3-devel \
    libsndfile \
    && yum clean all \
    && rm -rf /var/cache/yum || true

# Copy requirements first for better layer caching
COPY requirements.txt ${LAMBDA_TASK_ROOT}/

# Install Python dependencies
# Note: Lambda base image has /var/task as the working directory
# Use set -e to fail on any error
RUN set -e && \
    pip install --no-cache-dir --upgrade pip setuptools wheel

# Install core dependencies with pinned versions (pre-built wheels only)
# Install scipy EARLY with pre-built wheel (required by pyannote.audio and scenedetect)
# Pin versions that have pre-built wheels for Lambda's architecture
RUN set -e && \
    pip install --no-cache-dir \
    "pydantic==2.5.3" \
    "pydantic-settings==2.1.0" \
    "python-dotenv==1.0.0" \
    "boto3==1.34.0" \
    "numpy==1.24.3" \
    "scipy==1.11.4" \
    "Pillow==10.2.0" \
    "click==8.1.7" \
    "tqdm==4.66.1" && \
    python -c "import scipy; print(f'✅ scipy {scipy.__version__} installed')"

# Install LLM and API dependencies
# Used by: summarization, meeting_detection, embeddings (openai); store_factory, pinecone_store (pinecone)
# Pin httpx<0.28: openai 1.12 passes 'proxies' to httpx.Client; httpx 0.28+ dropped it -> Client.__init__() unexpected keyword 'proxies'
RUN set -e && \
    pip install --no-cache-dir \
    "httpx>=0.24,<0.28" \
    "openai==1.12.0" \
    "pinecone==5.0.1"

# faiss-cpu omitted: requires numpy>=1.25, which conflicts with our numpy 1.24.3 (pyannote, etc.).
# Processor uses Pinecone for indexing in Lambda; FAISS fallback only when running locally without Pinecone.

# Install media processing dependencies (opencv, librosa, scenedetect)
# Used by: main (cv2 frame count), scene_detection (scenedetect, cv2), media_processor (ffmpeg binary);
#          diarization (librosa for audio load). scipy already above.
# Use opencv-python-headless for Lambda (no GUI deps). Librosa --no-deps to avoid scikit-learn.
RUN set -e && \
    pip install --no-cache-dir \
    "opencv-python-headless==4.9.0.80" \
    "soundfile>=0.12.1" && \
    python -c "import cv2; print(f'✅ opencv-python-headless {cv2.__version__} installed')" && \
    (pip install --no-cache-dir "librosa>=0.10.0" --no-deps && \
     pip install --no-cache-dir "audioread>=2.1.9" "numba>=0.51.0" "packaging>=20.0" "scipy>=1.6.0" "numpy>=1.21.2" || \
     pip install --no-cache-dir "librosa>=0.10.0") && \
    pip install --no-cache-dir "scenedetect==0.6.2" && \
    python -c "import scenedetect; from scenedetect import open_video, SceneManager; print('✅ scenedetect (open_video) installed')" && \
    python -c "import librosa; print('✅ librosa installed')" || echo "⚠️ librosa installation failed (diarization may use fallback)"

# Install PyTorch (CPU version for Lambda) - REQUIRED for audio processing
# Using CPU-only version to reduce size and avoid CUDA dependencies
RUN set -e && \
    pip install --no-cache-dir \
    "torch==2.1.2" \
    "torchaudio==2.1.2" \
    --index-url https://download.pytorch.org/whl/cpu && \
    python -c "import torch; print(f'✅ torch {torch.__version__} installed')" && \
    python -c "import torchaudio; print(f'✅ torchaudio {torchaudio.__version__} installed')"

# Install pyannote.audio - REQUIRED for speaker diarization
# Used by: diarization (Pipeline, pyannote.core.Annotation).
# Transitive: pyannote.metrics (multilabel), pytorch_metric_learning (arcface), matplotlib (mixins),
#             pyannote.database 5.x (SegmentationProtocol), pyannote.pipeline.
# Must install after torch and scipy. Use --no-deps for several to avoid numpy 2.x / scikit-learn.
RUN set -e && \
    pip install --no-cache-dir \
    "einops>=0.6.0" \
    "huggingface-hub>=0.16.4,<0.20.0" \
    "pytorch-lightning>=2.0.0,<3.0.0" \
    "rich>=12.0.0" \
    "semver>=3.0.0" \
    "tensorboardX>=2.6" \
    "lazy_loader>=0.3" && \
    pip install --no-cache-dir "matplotlib>=3.7.0,<4" --no-deps && \
    pip install --no-cache-dir "cycler" "fonttools" "kiwisolver" "pyparsing" && \
    pip install --no-cache-dir "pytorch-metric-learning" --no-deps && \
    pip install --no-cache-dir "scikit-learn>=1.3.0,<1.4" && \
    pip install --no-cache-dir "asteroid-filterbanks>=0.4.0" && \
    pip install --no-cache-dir "pyannote.audio==3.1.1" --no-deps && \
    pip install --no-cache-dir "pyannote.pipeline" --no-deps && \
    pip install --no-cache-dir "optuna<4.0.0" && \
    pip install --no-cache-dir "torch-audiomentations" && \
    (pip install --no-cache-dir "pyannote.core==4.5" --no-deps && \
     pip install --no-cache-dir "typing-extensions" "sortedcontainers" || \
     pip install --no-cache-dir "pyannote.core==4.4" --no-deps && \
     pip install --no-cache-dir "typing-extensions" "sortedcontainers" || \
     pip install --no-cache-dir "pyannote.core==4.3" --no-deps && \
     pip install --no-cache-dir "typing-extensions" "sortedcontainers" || \
     echo "Warning: pyannote.core installation failed - diarization will be skipped") && \
    pip install --no-cache-dir "pandas<2.0.0" && \
    pip install --no-cache-dir "pyannote.database==5.0.1" --no-deps && \
    (pip install --no-cache-dir "pyannote.metrics>=3.2.0,<4.0.0" --no-deps && \
     pip install --no-cache-dir "scipy>=1.6.0" "numpy>=1.21.2" "typing-extensions" || \
     pip install --no-cache-dir "pyannote.metrics==3.3.0" --no-deps && \
     pip install --no-cache-dir "scipy>=1.6.0" "numpy>=1.21.2" "typing-extensions" || \
     pip install --no-cache-dir "pyannote.metrics==3.2.0" --no-deps && \
     pip install --no-cache-dir "scipy>=1.6.0" "numpy>=1.21.2" "typing-extensions" || \
     echo "Warning: pyannote.metrics installation failed - may cause import errors") && \
    pip install --no-cache-dir "pyYAML>=3.12" && \
    python -c "import pyannote.database; print('✅ pyannote.database installed and importable')" && \
    (python -c "import pyannote.metrics; print('✅ pyannote.metrics installed and importable')" || echo "⚠️ pyannote.metrics not importable (may be OK if not used)") && \
    python -c "import scipy; import torch; print('✅ scipy and torch available for pyannote')" && \
    python -c "import einops; print('✅ einops installed')" && \
    python -c "import pytorch_lightning; print('✅ pytorch_lightning installed')" && \
    python -c "import matplotlib; print('✅ matplotlib installed')" && \
    python -c "import pytorch_metric_learning; print('✅ pytorch_metric_learning installed')" && \
    python -c "import sklearn; print('✅ sklearn (scikit-learn) installed')" && \
    python -c "import asteroid_filterbanks; print('✅ asteroid_filterbanks installed')" && \
    python -c "from pyannote.audio import Pipeline; print('✅ pyannote.audio Pipeline importable')" && \
    python -c "import pyannote.audio; print('✅ pyannote.audio installed and fully functional')"

# Install ASR: faster-whisper (primary, ~4x faster) + openai-whisper (fallback)
# faster-whisper uses CTranslate2; openai-whisper uses PyTorch. Both use same model weights.
RUN set -e && \
    (pip install --no-cache-dir "tiktoken>=0.5.0" || \
     pip install --no-cache-dir "tiktoken==0.5.0" || echo "tiktoken optional") && \
    pip install --no-cache-dir "faster-whisper>=1.0.0" && \
    python -c "from faster_whisper import WhisperModel; print('✅ faster-whisper OK')" && \
    (pip install --no-cache-dir "openai-whisper==20231117" && \
     python -c "import whisper; print('✅ openai-whisper OK')" || \
     (pip install --no-cache-dir "openai-whisper==20231117" --no-deps || echo "⚠️ openai-whisper fallback failed"))

# Install FFmpeg (static linux amd64 build) and verify
RUN set -e && \
    curl -L "https://johnvansickle.com/ffmpeg/releases/ffmpeg-release-amd64-static.tar.xz" -o /tmp/ffmpeg-static.tar.xz && \
    mkdir -p /tmp/ffmpeg-static && \
    tar -xJf /tmp/ffmpeg-static.tar.xz -C /tmp/ffmpeg-static --strip-components=1 && \
    cp /tmp/ffmpeg-static/ffmpeg /usr/local/bin/ffmpeg && \
    cp /tmp/ffmpeg-static/ffprobe /usr/local/bin/ffprobe && \
    chmod +x /usr/local/bin/ffmpeg /usr/local/bin/ffprobe && \
    ffmpeg -version && \
    ffprobe -version && \
    echo "✅ FFmpeg and ffprobe installed successfully"

# Re-pin httpx<0.28 after all installs (huggingface-hub, whisper, etc. can upgrade it).
# OpenAI 1.12 + httpx 0.28+ -> Client.__init__() unexpected keyword 'proxies'. Force downgrade.
RUN set -e && \
    pip install --no-cache-dir "httpx>=0.24,<0.28" && \
    python -c "import httpx; print(f'✅ httpx {httpx.__version__} (must be <0.28)')" && \
    python -c "from openai import OpenAI; c=OpenAI(api_key='sk-fake'); print('✅ OpenAI client init OK (no proxies error)')"

# Verify critical Python dependencies (every package used by processor pipeline)
RUN set -e && \
    python -c "import pydantic; print('✅ pydantic OK')" && \
    python -c "import boto3; print('✅ boto3 OK')" && \
    python -c "import numpy; print('✅ numpy OK')" && \
    python -c "import scipy; print(f'✅ scipy {scipy.__version__} OK')" && \
    python -c "import openai; print('✅ openai OK')" && \
    python -c "import pinecone; print('✅ pinecone OK')" && \
    python -c "import torch; print(f'✅ torch {torch.__version__} OK')" && \
    python -c "import torchaudio; print('✅ torchaudio OK')" && \
    python -c "import cv2; print('✅ opencv OK')" && \
    python -c "import scenedetect; from scenedetect import open_video, SceneManager; print('✅ scenedetect OK')" && \
    python -c "import librosa; print('✅ librosa OK')" && \
    python -c "import pyannote.database; print('✅ pyannote.database OK')" && \
    python -c "import pyannote.metrics; print('✅ pyannote.metrics OK')" && \
    python -c "import matplotlib; print('✅ matplotlib OK')" && \
    python -c "import pytorch_metric_learning; print('✅ pytorch_metric_learning OK')" && \
    python -c "import sklearn; print('✅ sklearn OK')" && \
    python -c "import asteroid_filterbanks; print('✅ asteroid_filterbanks OK')" && \
    python -c "from pyannote.audio import Pipeline; print('✅ pyannote.audio Pipeline OK')" && \
    python -c "import pyannote.audio; print('✅ pyannote.audio OK')" && \
    python -c "import pytorch_lightning; print('✅ pytorch_lightning OK')" && \
    python -c "from faster_whisper import WhisperModel; print('✅ faster-whisper OK')" && \
    python -c "import whisper; print('✅ whisper OK')" && \
    echo "✅ All processor dependencies verified"

# Bake models into image (no runtime downloads)
RUN mkdir -p /opt/models/whisper /opt/models/huggingface/hub

RUN set -e && \
    python -c "from faster_whisper import WhisperModel; WhisperModel('base', device='cpu', download_root='/opt/models/whisper'); print('✅ Baked faster-whisper base')"

RUN set -e && \
    if [ -n "$HF_TOKEN" ]; then \
      HF_HOME=/opt/models/huggingface HF_HUB_CACHE=/opt/models/huggingface/hub HF_TOKEN="$HF_TOKEN" \
      python -c "from pyannote.audio import Pipeline; Pipeline.from_pretrained('pyannote/speaker-diarization-3.1'); print('✅ Baked pyannote diarization')"; \
    else \
      echo "⚠️ HF_TOKEN not set; pyannote will download at runtime"; \
    fi

ENV WHISPER_CACHE_DIR=/opt/models/whisper \
    HF_HOME=/opt/models/huggingface \
    HF_HUB_CACHE=/opt/models/huggingface/hub \
    HF_HUB_OFFLINE=1

# Copy application code
COPY src/ ${LAMBDA_TASK_ROOT}/src/
COPY config/ ${LAMBDA_TASK_ROOT}/config/

# Create lambda handler entry point
# The handler function is in src/workers/lambda_handler.py
# AWS Lambda will look for lambda_function.lambda_handler by default
COPY lambda_handler_processor.py ${LAMBDA_TASK_ROOT}/lambda_function.py

# Verify processor import works (catches circular imports)
RUN set -e && \
    python -c "from lambda_function import lambda_handler; print('processor import ok')" && \
    echo "✅ Processor import verified successfully"

# Set the CMD to your handler (AWS Lambda base image expects this format)
CMD [ "lambda_function.lambda_handler" ]
